{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>size</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_set.csv.zip</td>\n",
       "      <td>ÑµÁ·¼¯Êý¾Ý£¨Ñ¡ÊÖÐèÒª×ÔÐÐ½âÑ¹£©</td>\n",
       "      <td>236.11MB</td>\n",
       "      <td>https://tianchi-competition.oss-cn-hangzhou.al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_a.csv.zip</td>\n",
       "      <td>²âÊÔ¼¯A°ñÊý¾Ý£¨Ñ¡ÊÖÐèÒª×ÔÐÐ½âÑ¹£©</td>\n",
       "      <td>59.12MB</td>\n",
       "      <td>https://tianchi-competition.oss-cn-hangzhou.al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_a_sample_submit.csv</td>\n",
       "      <td>²âÊÔ¼¯A°ñÌá½»ÑùÀý</td>\n",
       "      <td>97.66KB</td>\n",
       "      <td>https://tianchi-competition.oss-cn-hangzhou.al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                        description      size  \\\n",
       "0         train_set.csv.zip     ÑµÁ·¼¯Êý¾Ý£¨Ñ¡ÊÖÐèÒª×ÔÐÐ½âÑ¹£©  236.11MB   \n",
       "1            test_a.csv.zip  ²âÊÔ¼¯A°ñÊý¾Ý£¨Ñ¡ÊÖÐèÒª×ÔÐÐ½âÑ¹£©   59.12MB   \n",
       "2  test_a_sample_submit.csv                  ²âÊÔ¼¯A°ñÌá½»ÑùÀý   97.66KB   \n",
       "\n",
       "                                                link  \n",
       "0  https://tianchi-competition.oss-cn-hangzhou.al...  \n",
       "1  https://tianchi-competition.oss-cn-hangzhou.al...  \n",
       "2  https://tianchi-competition.oss-cn-hangzhou.al...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('NLP_data_list_0715.csv',encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://tianchi-competition.oss-cn-hangzhou.al...\n",
       "1    https://tianchi-competition.oss-cn-hangzhou.al...\n",
       "2    https://tianchi-competition.oss-cn-hangzhou.al...\n",
       "Name: link, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_link = data['link'][0]\n",
    "test_link = data['link'][1]\n",
    "submit_link = data['link'][2]\n",
    "print(train_link)\n",
    "print(test_link)\n",
    "print(submit_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2967 6758 339 2021 1854 3731 4109 3792 4149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4464 486 6352 5619 2465 4802 1452 3137 5778 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7346 4068 5074 3747 5681 6093 1777 2226 7354 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7159 948 4866 2109 5520 2490 211 3956 5520 549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3646 3055 3055 2490 4659 6065 3370 5814 2465 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      2  2967 6758 339 2021 1854 3731 4109 3792 4149 15...\n",
       "1     11  4464 486 6352 5619 2465 4802 1452 3137 5778 54...\n",
       "2      3  7346 4068 5074 3747 5681 6093 1777 2226 7354 6...\n",
       "3      2  7159 948 4866 2109 5520 2490 211 3956 5520 549...\n",
       "4      3  3646 3055 3055 2490 4659 6065 3370 5814 2465 5..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_set.csv', sep = '\\t')\n",
    "test = pd.read_csv('test_a.csv',sep = '\\t')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['text']\n",
    "test_text = test['text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 49s, sys: 30.2 s, total: 8min 19s\n",
      "Wall time: 8min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<200000x6977 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 56074040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "train_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_word_features\n",
    "y_train = train['label']\n",
    "\n",
    "# 可以改变输入维度\n",
    "x_train_, x_valid_, y_train_, y_valid_ = train_test_split(X_train, y_train, test_size=0.2)\n",
    "X_test = test_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94910625 0.921020202773586\n",
      "CPU times: user 2.02 s, sys: 8.18 s, total: 10.2 s\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(C=4, n_jobs=16)\n",
    "clf.fit(x_train_, y_train_)\n",
    "\n",
    "y_pred = clf.predict(x_valid_)\n",
    "train_scores = clf.score(x_train_, y_train_)\n",
    "print(train_scores, f1_score(y_pred, y_valid_, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGB():\n",
    "    \n",
    "    def __init__(self, X_df, y_df):\n",
    "        self.X = X_df\n",
    "        self.y = y_df\n",
    "       \n",
    "    def train(self, param):\n",
    "        self.model = XGBClassifier(**param)\n",
    "        self.model.fit(self.X, self.y, eval_set=[(self.X, self.y)],\n",
    "                       eval_metric=['mlogloss'],\n",
    "                       early_stopping_rounds=10,  # 连续N次分值不再优化则提前停止\n",
    "                       verbose=False\n",
    "                      )\n",
    "        \n",
    "#         mode evaluation\n",
    "        train_result, train_proba = self.model.predict(self.X), self.model.predict_proba(self.X)\n",
    "        train_acc = accuracy_score(self.y, train_result)\n",
    "        train_auc = f1_score(self.y, train_proba, average='macro')\n",
    "        \n",
    "        print(\"Train acc: %.2f%% Train auc: %.2f\" % (train_acc*100.0, train_auc))\n",
    "        \n",
    "    def test(self, X_test, y_test):\n",
    "        result, proba = self.model.predict(X_test), self.model.predict_proba(X_test)\n",
    "        acc = accuracy_score(y_test, result)\n",
    "        f1 = f1_score(y_test, proba, average='macro')\n",
    "        \n",
    "        print(\"acc: %.2f%% F1_score: %.2f%%\" % (acc*100.0, f1))\n",
    "    \n",
    "    def grid(self, param_grid):\n",
    "        self.param_grid = param_grid\n",
    "        xgb_model = XGBClassifier(nthread=20)\n",
    "        clf = GridSearchCV(xgb_model, self.param_grid, scoring='f1_macro', cv=2, verbose=1)\n",
    "        clf.fit(self.X, self.y)\n",
    "        print(\"Best score: %f using parms: %s\" % (clf.best_score_, clf.best_params_))\n",
    "        return clf.best_params_, clf.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_train_, x_valid_, y_train_, y_valid_ = train_test_split(X_train[:, :300], y_train, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_test = test_word_features[:,:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.05,         #  (xgb’s “eta”)\n",
    "              'objective': 'multi:softmax', \n",
    "              'n_jobs': 16,\n",
    "              'n_estimators': 300,           # 树的个数\n",
    "              'max_depth': 10,               \n",
    "              'gamma': 0.5,                  # 惩罚项中叶子结点个数前的参数，Increasing this value will make model more conservative.\n",
    "              'reg_alpha': 0,               # L1 regularization term on weights.Increasing this value will make model more conservative.\n",
    "              'reg_lambda': 2,              # L2 regularization term on weights.Increasing this value will make model more conservative.\n",
    "              'min_child_weight' : 1,      # 叶子节点最小权重\n",
    "              'subsample':0.8,             # 随机选择80%样本建立决策树\n",
    "              'random_state':1           # 随机数\n",
    "             }\n",
    "model = XGB(x_train_, y_train_)\n",
    "model.train(param)\n",
    "model.test(x_valid_, y_valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGB(X_train, y_train)\n",
    "final_model.train(param)\n",
    "\n",
    "submission = pd.read_csv('./datalab/72510/test_a_sample_submit.csv')\n",
    "preds = final_model.model.predict(X_test)\n",
    "submission['label'] = preds\n",
    "submission.to_csv('./xgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
